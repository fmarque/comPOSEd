# comPOSEd

### About comPOSEd
**comPOSEd** is an innovative application that uses computer vision to enable users to add popular voice effects such as reverb, delay, distortion, and harmony in real-time through simple hand gestures. By combining machine-learning with intuitive controls, **comPOSEd** makes voice modulation both engaging and **accessible** for all.  

---

## How Does It Work?  
1. **Hand Gesture Recognition**: The application uses computer vision to track hand movements and interpret them as commands to switch the applied effect.  
2. **Audio Processing**: Voice effects are applied in real-time using AI-powered audio processing libraries such as Wavesurfer.  
3. **Immediate Feedback**: Users receive both visual and auditory feedback as they interact with the controls.  

---

## Features  

### Hand Gesture Control  
- Control audio effects effortlessly by performing gestures such as holding up a first, raising one, two, or three fingers. Each gesture is mapped to a specific effect, ensuring a seamless audio-mixing experience.  

### Accessible Interface  
- Immediate visual feedback confirms recognized gestures and the corresponding control applied.  
- Prioritizes **strong contrasting colors**, **clear fonts**, and **intuitive layouts** for ease of use.  

### Real-Time Feedback  
- Experience instant application of effects with no noticeable lag, allowing for a smooth and immersive experience.  

### Easy and Intuitive to Use  
- **comPOSEd** eliminates the complexity of traditional audio modulation setups by providing a straightforward, gesture-based approach.  

---

## How to Run It  

1. Ensure your device has all included packages and Node.js installed.

2.	Install any dependencies using "npm install" in the terminal while navigated to the project folder.

3.	Run "npm run dev" in the terminal

4. Click the link provided in the command

---

## Tools Used
	•	Backend: Python (Libraries/APIs: TensorFlow, Wavesurfer)
	•	Frontend: JavaScript (Libraries/APIs: React, Chakra)



